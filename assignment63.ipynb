{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f7a46-891c-47ba-9d6e-c455524d5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "ans:\n",
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we need to apply Bayes' theorem:\n",
    "\n",
    "P(smoker | uses health insurance plan) = P(uses health insurance plan | smoker) * P(smoker) / P(uses health insurance plan)\n",
    "\n",
    "We are given that 70% of the employees use the health insurance plan, so:\n",
    "\n",
    "P(uses health insurance plan) = 0.7\n",
    "\n",
    "We are also given that 40% of the employees who use the plan are smokers, so:\n",
    "\n",
    "P(uses health insurance plan | smoker) = 0.4\n",
    "\n",
    "Finally, we need to find the probability of a randomly selected employee being a smoker, which is given as:\n",
    "\n",
    "P(smoker) = ?\n",
    "\n",
    "This information is not given in the problem statement, so we cannot proceed further without making assumptions or obtaining additional data.\n",
    "\n",
    "Therefore, without knowing the probability of an employee being a smoker, we cannot calculate the probability that an employee is a smoker given that he/she uses the health \n",
    "insurance plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ed77e-cdce-4124-b0e8-792420d6193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "ans:\n",
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes algorithm used in machine learning for classification problems. The key difference between\n",
    "them lies in the type of data they can handle.\n",
    "\n",
    "Bernoulli Naive Bayes is used when the features (or variables) are binary (i.e., they can take only two values, typically 0 and 1). For example, in a spam email classification \n",
    "problem, the presence or absence of a particular word in an email can be represented as a binary feature. The Bernoulli Naive Bayes algorithm models the likelihood of each \n",
    "feature being present in the two classes (e.g., spam or not spam) and calculates the posterior probability of the class given the feature values.\n",
    "\n",
    "On the other hand, Multinomial Naive Bayes is used when the features represent discrete counts or frequencies, such as word counts in text data. In this case, the Multinomial \n",
    "Naive Bayes algorithm models the likelihood of each feature (word) occurring in each class and calculates the posterior probability of the class given the frequency of the \n",
    "features.\n",
    "\n",
    "In summary, Bernoulli Naive Bayes is used for binary data, while Multinomial Naive Bayes is used for count data. However, both algorithms assume that the features are \n",
    "independent of each other, given the class label (hence the \"Naive\" in the name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4a62a-6a09-4432-9150-29c9f8c85f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "ans:\n",
    "Bernoulli Naive Bayes algorithm assumes that the features (variables) are binary, taking values of 0 or 1. When there are missing values in the data, they are usually treated as\n",
    "a separate category, or they can be imputed (replaced with some estimated value). However, in Bernoulli Naive Bayes, the presence or absence of a feature (i.e., whether it has \n",
    "a value of 1 or 0) is the only relevant information for the classification, and missing values are treated as absent features (i.e., assigned a value of 0).\n",
    "\n",
    "For example, suppose we have a dataset with binary features representing whether a person exercises daily (1) or not (0), whether they drink coffee (1) or not (0), and whether \n",
    "they smoke (1) or not (0). If there is a missing value in the exercise column, it would be treated as the person not exercising (i.e., assigned a value of 0). The Bernoulli \n",
    "Naive Bayes algorithm then estimates the probability of each feature being present in each class, given the training data, and calculates the posterior probability of each \n",
    "class given the feature values, including the missing values treated as 0.\n",
    "\n",
    "However, it is important to note that imputing missing values in this way can potentially introduce bias into the model, especially if there is a high proportion of missing \n",
    "values or if the missing values are not missing at random. In such cases, it may be better to consider more advanced imputation methods or explore alternative models that can\n",
    "handle missing values more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225747e5-0293-4a0d-9e3a-7d966fe27ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "ans:\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification problems. In this case, the algorithm assumes that the feature values in each class are normally distributed\n",
    "(Gaussian distribution) and estimates the mean and variance of each feature for each class. Given a new set of feature values, the algorithm calculates the likelihood of each \n",
    "class based on the estimated mean and variance, and applies Bayes' theorem to calculate the posterior probability of each class given the feature values. The class with the \n",
    "highest posterior probability is then chosen as the predicted class for the new data point.\n",
    "\n",
    "There are different strategies to apply Gaussian Naive Bayes to multi-class classification problems. One approach is to use the one-vs-all (OvA) strategy, where a separate\n",
    "binary Gaussian Naive Bayes classifier is trained for each class, treating it as the positive class and the other classes as the negative class. For example, if there are three\n",
    "classes (A, B, and C), the OvA strategy would train three binary classifiers: A vs not A, B vs not B, and C vs not C. The predicted class for a new data point is then the one \n",
    "with the highest posterior probability among the three binary classifiers.\n",
    "\n",
    "Another approach is to use the one-vs-one (OvO) strategy, where a separate binary Gaussian Naive Bayes classifier is trained for each pair of classes, and the predicted class \n",
    "is the one that wins the most binary classifier comparisons. For example, if there are three classes (A, B, and C), the OvO strategy would train three binary classifiers: A vs \n",
    "B, A vs C, and B vs C. The predicted class for a new data point is then the one that wins the most binary comparisons among the three binary classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7439f8-665a-4c89-bebb-a9f97e45b1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5. Assignment:\n",
    "# Data preparation:\n",
    "# Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "# datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "# is spam or not based on several input features.\n",
    "# Implementation:\n",
    "# Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "# scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "# dataset. You should use the default hyperparameters for each classifier.\n",
    "# Results:\n",
    "# Report the following performance metrics for each classifier:\n",
    "# Accuracy\n",
    "# Precision\n",
    "# Recall\n",
    "# F1 score\n",
    "# Discussion:\n",
    "# Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "# the case? Are there any limitations of Naive Bayes that you observed?\n",
    "# Conclusion:\n",
    "# Summarise your findings and provide some suggestions for future work.\n",
    "\n",
    "# Note: Create your assignment in Jupyter notebook and upload it to GitHub & share that github repository\n",
    "# link through your dashboard. Make sure the repository is public.\n",
    "# Note: This dataset contains a binary classification problem with multiple features. The dataset is\n",
    "# relatively small, but it can be used to demonstrate the performance of the different variants of Naive\n",
    "# Bayes on a real-world problem\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "cols=['']\n",
    "df =pd.read_csv('spambase.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f915b5b-ec5d-4cbb-a19b-227d69d4d609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.40  \\\n",
       " 0     0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...   0.0   \n",
       " 1     0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...   0.0   \n",
       " 2     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...   0.0   \n",
       " 3     0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...   0.0   \n",
       " 4     0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...   0.0   \n",
       " ...    ...   ...     ...  ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       " 4595  0.31  0.00    0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 4596  0.00  0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 4597  0.30  0.00    0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 4598  0.96  0.00    0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 4599  0.00  0.00    0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " \n",
       "        0.41   0.42  0.43  0.778   0.44   0.45  3.756   61   278  \n",
       " 0     0.000  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  \n",
       " 1     0.010  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  \n",
       " 2     0.000  0.137   0.0  0.137  0.000  0.000  3.537   40   191  \n",
       " 3     0.000  0.135   0.0  0.135  0.000  0.000  3.537   40   191  \n",
       " 4     0.000  0.223   0.0  0.000  0.000  0.000  3.000   15    54  \n",
       " ...     ...    ...   ...    ...    ...    ...    ...  ...   ...  \n",
       " 4595  0.000  0.232   0.0  0.000  0.000  0.000  1.142    3    88  \n",
       " 4596  0.000  0.000   0.0  0.353  0.000  0.000  1.555    4    14  \n",
       " 4597  0.102  0.718   0.0  0.000  0.000  0.000  1.404    6   118  \n",
       " 4598  0.000  0.057   0.0  0.000  0.000  0.000  1.147    5    78  \n",
       " 4599  0.000  0.000   0.0  0.125  0.000  0.000  1.250    5    40  \n",
       " \n",
       " [4600 rows x 57 columns],\n",
       " 0       1\n",
       " 1       1\n",
       " 2       1\n",
       " 3       1\n",
       " 4       1\n",
       "        ..\n",
       " 4595    0\n",
       " 4596    0\n",
       " 4597    0\n",
       " 4598    0\n",
       " 4599    0\n",
       " Name: 1, Length: 4600, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6063689-c432-42e9-933e-c329eca2b9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         0   0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.40  \\\n",
       " 1898  0.00   0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 1370  0.00   0.00    0.00  0.0  0.00  0.00  0.00  1.11  0.00  0.00  ...   0.0   \n",
       " 3038  0.00   0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 2361  0.00   0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 156   0.00   0.00    0.00  0.0  1.36  0.45  0.45  0.00  0.00  0.00  ...   0.0   \n",
       " ...    ...    ...     ...  ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       " 4426  0.00   0.00    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 466   0.09   0.18    0.36  0.0  0.09  0.00  0.09  0.00  0.55  0.27  ...   0.0   \n",
       " 3092  0.00  14.28    0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 3772  0.00   0.00    0.00  0.0  1.23  0.00  0.00  0.00  0.00  0.00  ...   0.0   \n",
       " 860   0.14   0.00    0.28  0.0  0.09  0.24  0.04  0.04  0.24  0.00  ...   0.0   \n",
       " \n",
       "       0.41   0.42  0.43  0.778   0.44  0.45  3.756   61   278  \n",
       " 1898   0.0  0.000   0.0  0.000  0.000   0.0  5.500   10    11  \n",
       " 1370   0.0  0.208   0.0  0.208  0.416   0.0  3.950   23    79  \n",
       " 3038   0.0  0.000   0.0  0.000  0.000   0.0  1.526    7    87  \n",
       " 2361   0.0  0.000   0.0  0.000  0.000   0.0  4.228   53   148  \n",
       " 156    0.0  0.135   0.0  0.135  0.000   0.0  5.571   46   117  \n",
       " ...    ...    ...   ...    ...    ...   ...    ...  ...   ...  \n",
       " 4426   0.0  0.000   0.0  0.000  0.000   0.0  5.153   55    67  \n",
       " 466    0.0  0.056   0.0  0.341  0.085   0.0  7.273  103  1171  \n",
       " 3092   0.0  0.000   0.0  0.000  0.000   0.0  1.800    5     9  \n",
       " 3772   0.0  0.468   0.0  0.000  0.000   0.0  1.058    2    18  \n",
       " 860    0.0  0.061   0.0  0.007  0.099   0.0  1.867   14   521  \n",
       " \n",
       " [3680 rows x 57 columns],\n",
       " 1898    0\n",
       " 1370    1\n",
       " 3038    0\n",
       " 2361    0\n",
       " 156     1\n",
       "        ..\n",
       " 4426    0\n",
       " 466     1\n",
       " 3092    0\n",
       " 3772    0\n",
       " 860     1\n",
       " Name: 1, Length: 3680, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=42)\n",
    "X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d97a70-e569-4b2f-b14d-a6d53b766d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1615b842-b5a9-4bf7-836e-943d601c6aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd7441d-2987-4267-8618-06b342d9f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89055d6-8c89-4214-b7e2-0df0d74d7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dbc045d-b16e-428d-bab6-cde7716db72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[380 150]\n",
      " [ 20 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.72      0.82       530\n",
      "           1       0.71      0.95      0.81       390\n",
      "\n",
      "    accuracy                           0.82       920\n",
      "   macro avg       0.83      0.83      0.82       920\n",
      "weighted avg       0.85      0.82      0.82       920\n",
      "\n",
      "0.8152173913043478\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28171ce-60c8-412a-9f96-fe8b9db2e0fc",
   "metadata": {},
   "source": [
    "# for binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a185171-bc73-4ff6-8e43-d66777c71e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb=BernoulliNB()\n",
    "bnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ff8fe2d-388a-4248-803d-3e978c3b01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bnb= bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a3468d9-70dd-44fe-b407-a24864097515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[493  37]\n",
      " [ 80 310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       530\n",
      "           1       0.89      0.79      0.84       390\n",
      "\n",
      "    accuracy                           0.87       920\n",
      "   macro avg       0.88      0.86      0.87       920\n",
      "weighted avg       0.87      0.87      0.87       920\n",
      "\n",
      "0.8728260869565218\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_bnb))\n",
    "print(classification_report(y_test,y_pred_bnb))\n",
    "print(accuracy_score(y_test,y_pred_bnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66520be4-993b-4f83-ad6b-aaa27611c203",
   "metadata": {},
   "source": [
    "# for multinomial naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7a7aeaf-2189-4126-a2b7-4474b970ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3e11704-9f74-4093-a0ce-b3f3d8e1c6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da946f98-1c5e-47f2-9b6b-a7df23e4e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mnb= bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e551635f-e5e5-43df-b3f6-3c99257f4199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[493  37]\n",
      " [ 80 310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       530\n",
      "           1       0.89      0.79      0.84       390\n",
      "\n",
      "    accuracy                           0.87       920\n",
      "   macro avg       0.88      0.86      0.87       920\n",
      "weighted avg       0.87      0.87      0.87       920\n",
      "\n",
      "0.8728260869565218\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_mnb))\n",
    "print(classification_report(y_test,y_pred_mnb))\n",
    "print(accuracy_score(y_test,y_pred_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c4bb2-3e07-4d49-8738-62bdd3972d8b",
   "metadata": {},
   "source": [
    "# we can use bernouli naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b200c1-4d36-477a-a139-49a33c1e8221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
